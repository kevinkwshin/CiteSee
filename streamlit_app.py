import streamlit as st
import pandas as pd
from scholarly import scholarly
import io
from thefuzz import process, fuzz
import os
import numpy as np

# --- 1. í˜ì´ì§€ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜ ---
st.set_page_config(
    page_title="ë…¼ë¬¸ ê²€ìƒ‰ ë‹¤ìš´ë¡œë”",
    page_icon="ğŸ“š",
    layout="wide",
)

MAX_RESULTS_LIMIT = 200
MATCH_SCORE_THRESHOLD = 95
TOP_JOURNAL_IF_THRESHOLD = 8.0

JOURNAL_DATA_FILE = 'journal_impact_data_20250619_153150.csv'

# --- 2. í•µì‹¬ í•¨ìˆ˜ (ë°ì´í„° ë¡œë”©, ë§¤ì¹­, ìŠ¤íƒ€ì¼ë§) ---
@st.cache_data
def load_journal_db(file_path=JOURNAL_DATA_FILE):
    if not os.path.exists(file_path):
        return None, None
    try:
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        df.dropna(subset=['journal_title', 'impact_factor'], inplace=True)
        df['journal_title_upper'] = df['journal_title'].astype(str).str.upper() # ëŒ€ë¬¸ì ì»¬ëŸ¼ ì¶”ê°€

        def convert_if(value):
            if isinstance(value, str) and value.strip() == '<0.1':
                return 0.05
            try:
                return float(value)
            except ValueError:
                return np.nan
        df['impact_factor_numeric'] = df['impact_factor'].apply(convert_if) # ìˆ«ìí˜• IF ì»¬ëŸ¼ ì¶”ê°€
        df.dropna(subset=['impact_factor_numeric'], inplace=True)
        return df, df['journal_title_upper'].tolist() # ëŒ€ë¬¸ì ì €ë„ëª… ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    except Exception as e:
        st.error(f"ë°ì´í„° íŒŒì¼({file_path}) ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None, None

@st.cache_data
def get_journal_info_with_log(venue_from_scholar, db_df, journal_names_list_upper):
    """
    ì €ë„ëª… ë§¤ì¹­ì„ ì‹œë„í•˜ê³ , Impact Factorì™€ í•¨ê»˜ ë§¤ì¹­ ì‹œë„ ë¡œê·¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë°˜í™˜: (if_float, db_matched_journal_original_case, scholar_venue_processed, best_db_candidate_upper, score)
    ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ if_floatëŠ” np.nan, db_matched_journal_original_caseëŠ” "DB ë§¤ì¹­ ì‹¤íŒ¨"
    """
    if not venue_from_scholar or db_df is None or not journal_names_list_upper:
        return np.nan, "N/A", str(venue_from_scholar), "N/A", 0

    scholar_venue_processed = str(venue_from_scholar).strip().upper()
    if not scholar_venue_processed:
        return np.nan, "N/A", str(venue_from_scholar), "N/A", 0

    best_db_candidate_upper, score = process.extractOne(scholar_venue_processed, journal_names_list_upper, scorer=fuzz.ratio)

    if score >= MATCH_SCORE_THRESHOLD:
        # ë§¤ì¹­ëœ ëŒ€ë¬¸ì DB ì €ë„ëª…ìœ¼ë¡œ ì›ë³¸ DB ë°ì´í„°ì—ì„œ IFì™€ ì›ë³¸ ì €ë„ëª…(ëŒ€ì†Œë¬¸ì ìœ ì§€)ì„ ì°¾ìŒ
        matched_row = db_df.loc[db_df['journal_title_upper'] == best_db_candidate_upper]
        if not matched_row.empty:
            if_float = matched_row['impact_factor_numeric'].iloc[0]
            db_matched_journal_original_case = matched_row['journal_title'].iloc[0] # ì›ë³¸ ì¼€ì´ìŠ¤ ì €ë„ëª…
            return if_float, db_matched_journal_original_case, scholar_venue_processed, best_db_candidate_upper, score
        else: # ì´ ê²½ìš°ëŠ” ê±°ì˜ ë°œìƒí•˜ì§€ ì•Šì•„ì•¼ í•¨
            return np.nan, "DB ì¡°íšŒ ì˜¤ë¥˜", scholar_venue_processed, best_db_candidate_upper, score
    else:
        # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œì—ë„, ê°€ì¥ ìœ ì‚¬í–ˆë˜ í›„ë³´ì™€ ì ìˆ˜ëŠ” ë¡œê·¸ìš©ìœ¼ë¡œ ë°˜í™˜
        return np.nan, "DB ë§¤ì¹­ ì‹¤íŒ¨", scholar_venue_processed, best_db_candidate_upper, score


def classify_sjr(impact_factor_float):
    if pd.isna(impact_factor_float):
        return "N/A"
    try:
        score = float(impact_factor_float)
        if score >= 1.0: return "ìš°ìˆ˜"
        elif 0.5 <= score < 1.0: return "ì–‘í˜¸"
        elif 0.2 <= score < 0.5: return "ë³´í†µ"
        else: return "í•˜ìœ„"
    except (ValueError, TypeError):
        return "N/A"

def color_sjr_score(val_float_or_str): # ì…ë ¥ì´ ìˆ«ì ë˜ëŠ” "N/A" ë˜ëŠ” "<0.1" ë¬¸ìì—´ì¼ ìˆ˜ ìˆìŒ
    if isinstance(val_float_or_str, str):
        if val_float_or_str == "N/A":
            return 'color: grey;'
        elif val_float_or_str == "<0.1":
            score = 0.05
        else: # ìˆ«ìë¡œ ëœ ë¬¸ìì—´ (ì˜ˆ: "8.000")
            try:
                score = float(val_float_or_str)
            except ValueError:
                return 'color: grey;'
    elif pd.isna(val_float_or_str):
        return 'color: grey;'
    else: # float
        score = val_float_or_str

    try:
        if score >= 1.0: color = 'green'
        elif 0.5 <= score < 1.0: color = 'blue'
        elif 0.2 <= score < 0.5: color = 'orange'
        else: color = 'red' # 0.05 (<0.1)ë„ ì—¬ê¸°ì— í¬í•¨
        return f'color: {color}; font-weight: bold;'
    except (ValueError, TypeError): # í˜¹ì‹œ ëª¨ë¥¼ ë‹¤ë¥¸ íƒ€ì… ì—ëŸ¬ ë°©ì§€
        return 'color: grey;'


@st.cache_data
def convert_df_to_csv(df: pd.DataFrame):
    df_copy = df.copy()
    for col in df_copy.columns:
        df_copy[col] = df_copy[col].astype(str)
    return df_copy.to_csv(index=False).encode('utf-8-sig')


# --- 3. UI ë³¸ë¬¸ êµ¬ì„± ---
st.title("ğŸ“š ë…¼ë¬¸ ê²€ìƒ‰ ë° ì •ë³´ ë‹¤ìš´ë¡œë”")
st.markdown(f"""
Google Scholarì—ì„œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³ , Impact Factorë¥¼ í•¨ê»˜ ì¡°íšŒí•©ë‹ˆë‹¤. (ìµœëŒ€ **{MAX_RESULTS_LIMIT}ê°œ**ê¹Œì§€ í‘œì‹œ)

**ì €ë„ëª… ë§¤ì¹­:** Google Scholarì˜ ì €ë„ëª…ê³¼ ë‚´ë¶€ DBì˜ ì €ë„ëª… (ëª¨ë‘ **ëŒ€ë¬¸ìë¡œ ë³€í™˜ í›„ ë¹„êµ**) ê°„ ìœ ì‚¬ë„ ì ìˆ˜ê°€ **{MATCH_SCORE_THRESHOLD}% ì´ìƒ**ì¼ ê²½ìš°ì—ë§Œ Impact Factorë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
**ğŸ† Top ì €ë„ ê¸°ì¤€:** Impact Factor **{TOP_JOURNAL_IF_THRESHOLD}ì  ì´ìƒ**ì¸ ì €ë„.
""")

db_df, journal_names_upper_list = load_journal_db() # ì´ì œ journal_names_upper_listëŠ” ëŒ€ë¬¸ì
if db_df is None:
    st.error(f"âš ï¸ `{JOURNAL_DATA_FILE}` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•±ê³¼ ë™ì¼í•œ í´ë”ì— í•´ë‹¹ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    st.success(f"âœ… ì´ {len(db_df):,}ê°œì˜ ì €ë„ ì •ë³´ê°€ ë‹´ê¸´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. (ì €ë„ëª…ì€ ëŒ€ë¬¸ìë¡œ í†µì¼í•˜ì—¬ ë§¤ì¹­)")

    with st.expander("ğŸ’¡ ê²°ê³¼ í…Œì´ë¸” í•´ì„ ê°€ì´ë“œ ë³´ê¸°"):
        st.markdown(f"""
        - **ğŸ† Top ì €ë„**: Impact Factorê°€ {TOP_JOURNAL_IF_THRESHOLD}ì  ì´ìƒì¸ ê²½ìš° í‘œì‹œë©ë‹ˆë‹¤.
        - **ì €ë„ëª… (ê²€ìƒ‰ê²°ê³¼)**: Google Scholarì—ì„œ ê°€ì ¸ì˜¨ ì›ë³¸ ì €ë„ëª…ì…ë‹ˆë‹¤.
        - **DB ì €ë„ëª… (ë§¤ì¹­ì‹œ)**: DBì—ì„œ ë§¤ì¹­ëœ ì €ë„ëª…(ì›ë³¸ ëŒ€ì†Œë¬¸ì)ì…ë‹ˆë‹¤. ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ "DB ë§¤ì¹­ ì‹¤íŒ¨"ë¡œ í‘œì‹œë©ë‹ˆë‹¤.
        - **ë§¤ì¹­ ì ìˆ˜**: Google Scholar ì €ë„ëª…(ëŒ€ë¬¸ìí™”)ê³¼ DB ì €ë„ëª…(ëŒ€ë¬¸ìí™”) ê°„ì˜ ìœ ì‚¬ë„ì…ë‹ˆë‹¤.
        - **Impact Factor ë“±ê¸‰**: ìš°ìˆ˜(IF >= 1.0), ì–‘í˜¸(0.5 <= IF < 1.0), ë³´í†µ(0.2 <= IF < 0.5), í•˜ìœ„(IF < 0.2)
        """)

    with st.form(key='search_form'):
        st.subheader("ğŸ” ê²€ìƒ‰ ì¡°ê±´ ì…ë ¥")
        col1, col2 = st.columns(2)
        with col1:
            author = st.text_input("ì €ì (ì„ íƒ ì‚¬í•­)", placeholder="ì˜ˆ: Hinton G")
        with col2:
            keyword = st.text_input("í‚¤ì›Œë“œ (ì„ íƒ ì‚¬í•­)", placeholder="ì˜ˆ: deep learning")

        only_if_found = st.checkbox("Impact Factor ì •ë³´ê°€ ìˆëŠ” ì €ë„ë§Œ ì°¾ê¸° (DBì—ì„œ ë§¤ì¹­ë˜ëŠ” ì €ë„ë§Œ í‘œì‹œ)", value=True)

        submit_button = st.form_submit_button(label='ê²€ìƒ‰ ì‹œì‘')

    if submit_button and (author or keyword):
        query_parts = []
        if keyword: query_parts.append(keyword)
        if author: query_parts.append(f'author:"{author}"')
        query = " ".join(query_parts)

        failed_matches_log = [] # ë§¤ì¹­ ì‹¤íŒ¨ ë¡œê·¸ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

        with st.spinner(f"'{query}' ì¡°ê±´ìœ¼ë¡œ ë…¼ë¬¸ì„ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                search_query = scholarly.search_pubs(query)
                results = []
                for i, pub in enumerate(search_query):
                    if i >= MAX_RESULTS_LIMIT:
                        st.info(f"ê²€ìƒ‰ ê²°ê³¼ê°€ ë§ì•„ ìµœëŒ€ {MAX_RESULTS_LIMIT}ê°œê¹Œì§€ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
                        break

                    bib = pub.get('bib', {})
                    venue_from_scholar = bib.get('venue', 'N/A')

                    if_float, db_matched_journal_original, scholar_venue_processed, best_db_candidate, score_val = get_journal_info_with_log(
                        venue_from_scholar, db_df, journal_names_upper_list
                    )

                    # ìƒì„¸ ë¡œê·¸ ê¸°ë¡ (ì ìˆ˜ê°€ 0ë³´ë‹¤ í¬ê³  ì„ê³„ê°’ ë¯¸ë§Œì¸ ê²½ìš°)
                    if pd.isna(if_float) and score_val > 0 and score_val < MATCH_SCORE_THRESHOLD :
                        failed_matches_log.append({
                            "ë…¼ë¬¸ ì œëª©": bib.get('title', 'N/A')[:50] + "...", # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
                            "GS ì €ë„ëª… (ì›ë³¸)": venue_from_scholar,
                            "GS ì €ë„ëª… (ì²˜ë¦¬ë¨)": scholar_venue_processed,
                            "DB ìµœìœ ì‚¬ í›„ë³´ (ì²˜ë¦¬ë¨)": best_db_candidate,
                            "ìœ ì‚¬ë„ ì ìˆ˜": score_val
                        })
                    
                    if only_if_found and pd.isna(if_float):
                        continue
                    
                    top_journal_icon = ""
                    if not pd.isna(if_float) and if_float >= TOP_JOURNAL_IF_THRESHOLD:
                        top_journal_icon = "ğŸ†"
                    
                    results.append({
                        "Top ì €ë„": top_journal_icon,
                        "ì œëª© (Title)": bib.get('title', 'N/A'),
                        "ì €ì (Authors)": ", ".join(bib.get('author', ['N/A'])),
                        "ì—°ë„ (Year)": bib.get('pub_year', 'N/A'),
                        "ì €ë„ëª… (ê²€ìƒ‰ê²°ê³¼)": venue_from_scholar,
                        "DB ì €ë„ëª… (ë§¤ì¹­ì‹œ)": db_matched_journal_original,
                        "ë§¤ì¹­ ì ìˆ˜ (%)": score_val if score_val > 0 else "N/A",
                        "_Impact Factor_numeric": if_float, # ìˆ«ìí˜• IFëŠ” ë‚´ë¶€ ê³„ì‚°ìš©ìœ¼ë¡œ ìˆ¨ê¹€ (ë˜ëŠ” ë‹¤ë¥¸ ì´ë¦„)
                        "Impact Factor": f"{if_float:.3f}" if not pd.isna(if_float) and if_float != 0.05 else ("<0.1" if if_float == 0.05 else "N/A"),
                        "í”¼ì¸ìš© ìˆ˜": pub.get('num_citations', 0),
                        "ë…¼ë¬¸ ë§í¬": pub.get('pub_url', '#'),
                    })

                if not results:
                    st.warning("ì¡°ê±´ì— ë§ëŠ” ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. (í•„í„°ë¥¼ í•´ì œí•˜ê±°ë‚˜ ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”)")
                else:
                    subheader_text = f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ)"
                    if only_if_found:
                        subheader_text += " - Impact Factor ì •ë³´ê°€ ìˆëŠ” ì €ë„ë§Œ í•„í„°ë§ë¨"
                    st.subheader(subheader_text)

                    df_results = pd.DataFrame(results)
                    df_results['IF ë“±ê¸‰'] = df_results['_Impact Factor_numeric'].apply(classify_sjr) # ìˆ«ìí˜• IFë¡œ ë“±ê¸‰ ê³„ì‚°
                    
                    df_display = df_results[[
                        "Top ì €ë„", "ì œëª© (Title)", "ì €ì (Authors)", "ì—°ë„ (Year)",
                        "ì €ë„ëª… (ê²€ìƒ‰ê²°ê³¼)", "DB ì €ë„ëª… (ë§¤ì¹­ì‹œ)", "Impact Factor", "IF ë“±ê¸‰",
                        "í”¼ì¸ìš© ìˆ˜", "ë§¤ì¹­ ì ìˆ˜ (%)", "ë…¼ë¬¸ ë§í¬"
                    ]]

                    st.dataframe(
                        df_display.style.applymap(color_sjr_score, subset=['Impact Factor']),
                        use_container_width=True,
                        column_config={"ë…¼ë¬¸ ë§í¬": st.column_config.LinkColumn("ë°”ë¡œê°€ê¸°", display_text="ğŸ”— Link")},
                        hide_index=True
                    )

                    csv_data = convert_df_to_csv(df_display)
                    st.download_button(
                        label="ğŸ“„ ê²°ê³¼ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                        data=csv_data,
                        file_name=f'search_{query.replace(" ", "_").replace(":", "")}.csv',
                        mime='text/csv'
                    )
                
                # ë§¤ì¹­ ì‹¤íŒ¨ ë¡œê·¸ í‘œì‹œ
                if failed_matches_log:
                    st.subheader("âš ï¸ ì €ë„ëª… ë§¤ì¹­ ì‹¤íŒ¨ ìƒì„¸ ë¡œê·¸ (ìœ ì‚¬ë„ > 0ì , ì„ê³„ê°’ ë¯¸ë§Œ)")
                    st.caption(f"ì•„ë˜ëŠ” Impact Factorë¥¼ ì°¾ì§€ ëª»í–ˆìœ¼ë‚˜, DBì—ì„œ ì–´ëŠ ì •ë„ ìœ ì‚¬í•œ ì €ë„ì„ ì°¾ì•˜ë˜ ê²½ìš°ì…ë‹ˆë‹¤. (í˜„ì¬ ë§¤ì¹­ ì„ê³„ê°’: {MATCH_SCORE_THRESHOLD}%)")
                    df_failed_log = pd.DataFrame(failed_matches_log)
                    st.dataframe(df_failed_log, use_container_width=True, hide_index=True)

            except Exception as e:
                st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)
    elif submit_button and not (author or keyword):
        st.warning("ì €ì ë˜ëŠ” í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ ì´ìƒì„ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
