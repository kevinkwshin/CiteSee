import streamlit as st
import pandas as pd
from scholarly import scholarly
import io
import requests
import time

# ----------------------------------
# í˜ì´ì§€ ì„¤ì •
# ----------------------------------
st.set_page_config(
    page_title="Scholar ê²€ìƒ‰ê¸° (S2 API ì—°ë™)",
    page_icon="âœ¨",
    layout="wide",
)

# ----------------------------------
# Semantic Scholar API ì—°ë™ í•¨ìˆ˜
# ----------------------------------
@st.cache_data(ttl=3600)  # API ê²°ê³¼ë¥¼ 1ì‹œê°„ ë™ì•ˆ ìºì‹±í•˜ì—¬ ë°˜ë³µ í˜¸ì¶œ ë°©ì§€
def get_journal_info_from_s2(journal_name: str):
    """
    Semantic Scholar (S2) APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ë„ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    :param journal_name: Google Scholarì—ì„œ ê°€ì ¸ì˜¨ ì €ë„ ì´ë¦„
    :return: (ì˜í–¥ë ¥ ì ìˆ˜, í™ˆí˜ì´ì§€ URL) íŠœí”Œ
    """
    if not journal_name:
        return "N/A", "#"

    try:
        # S2ì˜ ì €ë„ ê²€ìƒ‰ API ì—”ë“œí¬ì¸íŠ¸
        # ì €ë„ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰í•˜ë¯€ë¡œ, ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì²« ë²ˆì§¸ ê²°ê³¼ë¥¼ ì‚¬ìš©
        response = requests.get(
            "https://api.semanticscholar.org/graph/v1/journal/search",
            params={"query": journal_name, "fields": "journalName,homepage,latestImpactFactor"},
            timeout=10
        )
        response.raise_for_status()
        data = response.json()

        if data.get("data") and len(data["data"]) > 0:
            journal_data = data["data"][0] # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì²« ë²ˆì§¸ ì €ë„ ì •ë³´ ì‚¬ìš©
            
            # S2 API ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼ í‚¤ ì´ë¦„ì´ ë°”ë€” ìˆ˜ ìˆìŒ (ë¬¸ì„œ í™•ì¸ í•„ìš”)
            # í˜„ì¬ëŠ” 'latestImpactFactor'ê°€ ê³µì‹ í•„ë“œëŠ” ì•„ë‹ˆì§€ë§Œ, ìˆë‹¤ê³  ê°€ì •í•˜ê³  ì¡°íšŒ
            # ì‹¤ì œë¡œëŠ” influenceScore, citationCount ë“±ì„ í™œìš©í•  ìˆ˜ ìˆìŒ
            impact_factor = journal_data.get("latestImpactFactor", "N/A")
            homepage = journal_data.get("homepage", "#")
            
            # ê°’ì´ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
            if impact_factor is None: impact_factor = "N/A"
            if homepage is None: homepage = "#"

            return impact_factor, homepage
        else:
            return "N/A", "#"
            
    except requests.exceptions.RequestException as e:
        # API ìš”ì²­ì´ ë„ˆë¬´ ë§ê±°ë‚˜ ì‹¤íŒ¨í•  ê²½ìš°
        print(f"API Error for '{journal_name}': {e}")
        return "API ì˜¤ë¥˜", "#"
    except Exception as e:
        print(f"Data parsing error for '{journal_name}': {e}")
        return "ë°ì´í„° ì˜¤ë¥˜", "#"

# ----------------------------------
# ë°ì´í„° ë³€í™˜ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
# ----------------------------------
@st.cache_data
def to_excel(df: pd.DataFrame):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    return output.getvalue()

@st.cache_data
def to_csv(df: pd.DataFrame):
    return df.to_csv(index=False).encode('utf-8-sig')


# ----------------------------------
# Streamlit ì•± UI êµ¬ì„±
# ----------------------------------
st.title("âœ¨ Google Scholar ê²€ìƒ‰ê¸° (Semantic Scholar API ì—°ë™)")
st.markdown("""
Google Scholarì—ì„œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³ , **[Semantic Scholar API](https://www.semanticscholar.org/product/api)**ë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì €ë„ ì •ë³´ë¥¼ í•¨ê»˜ ì¡°íšŒí•©ë‹ˆë‹¤.
- `journal_if_data.csv` íŒŒì¼ì´ ë” ì´ìƒ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
- ê²€ìƒ‰ëœ ì €ë„ëª…ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì €ë„ì˜ **ì˜í–¥ë ¥ ì ìˆ˜(Impact Factor)**ì™€ **í™ˆí˜ì´ì§€** ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
""")

# --- ì…ë ¥ í¼ ---
with st.form(key='search_form'):
    keyword = st.text_input("**ğŸ‘‰ ê²€ìƒ‰ì–´(Keyword)ë¥¼ ì…ë ¥í•˜ì„¸ìš”**", placeholder="ì˜ˆ: large language models")
    num_results = st.number_input(
        "**ğŸ‘‰ ê²€ìƒ‰í•  ë…¼ë¬¸ ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”**", 
        min_value=5, max_value=30, value=10, step=5,
        help="API í˜¸ì¶œ ì œí•œìœ¼ë¡œ ì¸í•´ í•œ ë²ˆì— ë„ˆë¬´ ë§ì€ ìˆ˜ë¥¼ ê²€ìƒ‰í•˜ë©´ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    submit_button = st.form_submit_button(label='ğŸ” ê²€ìƒ‰ ì‹œì‘')

# --- ê²€ìƒ‰ ë¡œì§ ë° ê²°ê³¼ í‘œì‹œ ---
if submit_button and keyword:
    with st.spinner(f"'{keyword}' ë…¼ë¬¸ ê²€ìƒ‰ ë° S2 APIë¡œ ì €ë„ ì •ë³´ ì¡°íšŒ ì¤‘..."):
        try:
            search_query = scholarly.search_pubs(keyword)
            results = []
            
            progress_bar = st.progress(0, text="ë…¼ë¬¸ ì²˜ë¦¬ ì‹œì‘...")

            for i, pub in enumerate(search_query):
                if i >= num_results:
                    break
                
                # API í˜¸ì¶œ ì‚¬ì´ì˜ ê°„ê²©ì„ ë‘ì–´ Rate Limit ë°©ì§€
                time.sleep(0.5) 
                
                bib = pub.get('bib', {})
                venue = bib.get('venue', 'N/A')
                
                # ì‹¤ì‹œê°„ìœ¼ë¡œ S2 APIë¥¼ í†µí•´ ì €ë„ ì •ë³´ ì¡°íšŒ
                impact_factor, journal_homepage = get_journal_info_from_s2(venue)
                
                results.append({
                    "ì œëª© (Title)": bib.get('title', 'N/A'),
                    "ì €ì (Authors)": ", ".join(bib.get('author', ['N/A'])),
                    "ì—°ë„ (Year)": bib.get('pub_year', 'N/A'),
                    "ì €ë„/ì¶œíŒë¬¼ (Journal/Venue)": venue,
                    "ì €ë„ IF (S2)": impact_factor,
                    "í”¼ì¸ìš© ìˆ˜ (Citations)": pub.get('num_citations', 0),
                    "ë…¼ë¬¸ ë§í¬": pub.get('pub_url', '#'),
                    "ì €ë„ í™ˆí˜ì´ì§€": journal_homepage,
                })

                # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
                progress_percentage = (i + 1) / num_results
                progress_bar.progress(progress_percentage, text=f"ë…¼ë¬¸ ì²˜ë¦¬ ì¤‘... {i+1}/{num_results}")

            progress_bar.empty()

            if not results:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
            else:
                df = pd.DataFrame(results)
                
                st.success(f"ì´ {len(df)}ê°œì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                
                st.dataframe(
                    df,
                    use_container_width=True,
                    # ë§í¬ ì»¬ëŸ¼ ì„¤ì •
                    column_config={
                        "ë…¼ë¬¸ ë§í¬": st.column_config.LinkColumn("ë…¼ë¬¸ ë°”ë¡œê°€ê¸°", display_text="ğŸ”— Paper"),
                        "ì €ë„ í™ˆí˜ì´ì§€": st.column_config.LinkColumn("í™ˆí˜ì´ì§€", display_text="ğŸ  Homepage")
                    },
                    hide_index=True,
                )
                
                st.markdown("---")
                st.subheader("ğŸ“¥ íŒŒì¼ ë‹¤ìš´ë¡œë“œ")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.download_button(
                        label="ğŸ“„ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                        data=to_csv(df),
                        file_name=f's2_scholar_results_{keyword.replace(" ", "_")}.csv',
                        mime='text/csv',
                    )
                with col2:
                    st.download_button(
                        label="ğŸ“Š Excel íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                        data=to_excel(df),
                        file_name=f's2_scholar_results_{keyword.replace(" ", "_")}.xlsx',
                        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                    )

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.info("Google Scholar ë˜ëŠ” Semantic Scholarì˜ ìš”ì²­ ì œí•œ(rate limit)ì— ë„ë‹¬í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

elif submit_button and not keyword:
    st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
