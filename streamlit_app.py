import streamlit as st
import pandas as pd
from scholarly import scholarly
import io
from thefuzz import process, fuzz
import os
import numpy as np # numpy ì¶”ê°€

# --- 1. í˜ì´ì§€ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜ ---
st.set_page_config(
    page_title="ë…¼ë¬¸ ê²€ìƒ‰ ë‹¤ìš´ë¡œë”",
    page_icon="ğŸ“š",
    layout="wide",
)

MAX_RESULTS_LIMIT = 200
MATCH_SCORE_THRESHOLD = 95 # ì €ë„ëª… ë§¤ì¹­ ì„ê³„ê°’
TOP_JOURNAL_IF_THRESHOLD = 8.0 # Top ì €ë„ IF ê¸°ì¤€

JOURNAL_DATA_FILE = 'journal_impact_data_20250619_153150.csv'

# --- 2. í•µì‹¬ í•¨ìˆ˜ (ë°ì´í„° ë¡œë”©, ë§¤ì¹­, ìŠ¤íƒ€ì¼ë§) ---
@st.cache_data
def load_journal_db(file_path=JOURNAL_DATA_FILE):
    if not os.path.exists(file_path):
        return None, None
    try:
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        # í•„ìˆ˜ ì»¬ëŸ¼ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df.dropna(subset=['journal_title', 'impact_factor'], inplace=True)

        # journal_titleì„ ëŒ€ë¬¸ìë¡œ ë³€í™˜ ë° ë¬¸ìì—´ë¡œ í†µì¼
        df['journal_title'] = df['journal_title'].astype(str).str.upper()

        # impact_factor ì²˜ë¦¬: '<0.1'ì„ 0.05ë¡œ, ê·¸ ì™¸ ìˆ«ìë¡œ ë³€í™˜, ë³€í™˜ ë¶ˆê°€ ì‹œ NaN
        def convert_if(value):
            if isinstance(value, str) and value.strip() == '<0.1':
                return 0.05
            try:
                return float(value)
            except ValueError:
                return np.nan # ìˆ«ìë¡œ ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ê²½ìš° NaN ì²˜ë¦¬

        df['impact_factor'] = df['impact_factor'].apply(convert_if)
        df.dropna(subset=['impact_factor'], inplace=True) # IF ë³€í™˜ í›„ NaNì´ ëœ í–‰ ì œê±°

        return df, df['journal_title'].tolist() # journal_names_listëŠ” ì´ì œ ëª¨ë‘ ëŒ€ë¬¸ì
    except Exception as e:
        st.error(f"ë°ì´í„° íŒŒì¼({file_path}) ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None, None

@st.cache_data
def get_journal_info(venue_from_scholar, db_df, journal_names_list_upper):
    """
    ì£¼ì–´ì§„ ì €ë„ëª…(venue_from_scholar)ì„ DBì™€ ë§¤ì¹­í•˜ì—¬ Impact Factor ë“±ì˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    DBì˜ ì €ë„ëª… ë¦¬ìŠ¤íŠ¸(journal_names_list_upper)ëŠ” ì´ë¯¸ ëŒ€ë¬¸ìë¡œ ë³€í™˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    ë°˜í™˜ê°’: (impact_factor_float, matched_db_journal_name_upper, match_score)
    ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ: (np.nan, "DB ë§¤ì¹­ ì‹¤íŒ¨", score)
    """
    if not venue_from_scholar or db_df is None or not journal_names_list_upper:
        return np.nan, "N/A", 0

    processed_venue = str(venue_from_scholar).strip().upper() # Google Scholar ì €ë„ëª…ë„ ëŒ€ë¬¸ìë¡œ
    if not processed_venue:
        return np.nan, "N/A", 0

    # journal_names_list_upper (DB ì €ë„ëª… ë¦¬ìŠ¤íŠ¸)ëŠ” ì´ë¯¸ ëŒ€ë¬¸ì
    match_upper, score = process.extractOne(processed_venue, journal_names_list_upper, scorer=fuzz.ratio)

    if score >= MATCH_SCORE_THRESHOLD:
        # match_upper (DBì˜ ëŒ€ë¬¸ì ì €ë„ëª…)ë¥¼ ì‚¬ìš©í•˜ì—¬ Impact Factor ì¡°íšŒ
        impact_factor_series = db_df.loc[db_df['journal_title'] == match_upper, 'impact_factor']
        if not impact_factor_series.empty:
            impact_factor_value = impact_factor_series.iloc[0]
            # load_journal_dbì—ì„œ ì´ë¯¸ floatìœ¼ë¡œ ë³€í™˜í–ˆìœ¼ë¯€ë¡œ ë°”ë¡œ ë°˜í™˜
            return impact_factor_value, match_upper, score
        else:
            return np.nan, "DB ì¡°íšŒ ì˜¤ë¥˜", score
    else:
        return np.nan, "DB ë§¤ì¹­ ì‹¤íŒ¨", score

def classify_sjr(impact_factor_float): # ì…ë ¥ê°’ì„ floatìœ¼ë¡œ ê°€ì •
    if pd.isna(impact_factor_float): # np.nan ë˜ëŠ” Noneì¸ ê²½ìš°
        return "N/A"
    try:
        score = float(impact_factor_float) # ì´ë¯¸ floatì¼ ìˆ˜ ìˆì§€ë§Œ, ì•ˆì „í•˜ê²Œ ë³€í™˜
        if score >= 1.0: return "ìš°ìˆ˜"
        elif 0.5 <= score < 1.0: return "ì–‘í˜¸"
        elif 0.2 <= score < 0.5: return "ë³´í†µ"
        else: return "í•˜ìœ„" # 0.05ì™€ ê°™ì€ ê°’ë„ ì—¬ê¸°ì— í¬í•¨
    except (ValueError, TypeError):
        return "N/A"

def color_sjr_score(val_float): # ì…ë ¥ê°’ì„ float ë˜ëŠ” NaNìœ¼ë¡œ ê°€ì •
    if pd.isna(val_float):
        return 'color: grey;'
    try:
        score = float(val_float)
        if score >= 1.0: color = 'green'
        elif 0.5 <= score < 1.0: color = 'blue'
        elif 0.2 <= score < 0.5: color = 'orange'
        else: color = 'red'
        return f'color: {color}; font-weight: bold;'
    except (ValueError, TypeError):
        return 'color: grey;'

@st.cache_data
def convert_df_to_csv(df: pd.DataFrame):
    # IFê°€ ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš° (ì˜ˆ: NaNì„ ë¬¸ìì—´ "N/A"ë¡œ ë°”ê¾¼ í›„)ë¥¼ ëŒ€ë¹„í•´ ëª¨ë“  ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ì €ì¥
    df_copy = df.copy()
    for col in df_copy.columns:
        if df_copy[col].dtype == 'object': # ë¬¸ìì—´ë¡œ ë³€í™˜ëœ ìˆ«ìí˜• ì»¬ëŸ¼ ë“±ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            df_copy[col] = df_copy[col].astype(str)
    return df_copy.to_csv(index=False).encode('utf-8-sig')


# --- 3. UI ë³¸ë¬¸ êµ¬ì„± ---
st.title("ğŸ“š ë…¼ë¬¸ ê²€ìƒ‰ ë° ì •ë³´ ë‹¤ìš´ë¡œë”")
st.markdown(f"""
Google Scholarì—ì„œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³ , Impact Factorë¥¼ í•¨ê»˜ ì¡°íšŒí•©ë‹ˆë‹¤. (ìµœëŒ€ **{MAX_RESULTS_LIMIT}ê°œ**ê¹Œì§€ í‘œì‹œ)

**ì €ë„ëª… ë§¤ì¹­ ì •í™•ë„:** Google Scholarì˜ ì €ë„ëª…ê³¼ ë‚´ë¶€ DBì˜ ì €ë„ëª…(ëª¨ë‘ ëŒ€ë¬¸ìë¡œ ë³€í™˜ í›„ ë¹„êµ) ê°„ ìœ ì‚¬ë„ ì ìˆ˜ê°€ **{MATCH_SCORE_THRESHOLD}% ì´ìƒ**ì¼ ê²½ìš°ì—ë§Œ Impact Factorë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
**ğŸ† Top ì €ë„ ê¸°ì¤€:** Impact Factor **{TOP_JOURNAL_IF_THRESHOLD}ì  ì´ìƒ**ì¸ ì €ë„.
""")

db_df, journal_names_upper = load_journal_db() # journal_names_upperëŠ” ëŒ€ë¬¸ìí™”ëœ ë¦¬ìŠ¤íŠ¸
if db_df is None:
    st.error(f"âš ï¸ `{JOURNAL_DATA_FILE}` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•±ê³¼ ë™ì¼í•œ í´ë”ì— í•´ë‹¹ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    st.success(f"âœ… ì´ {len(db_df):,}ê°œì˜ ì €ë„ ì •ë³´ê°€ ë‹´ê¸´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    with st.expander("ğŸ’¡ ê²°ê³¼ í…Œì´ë¸” í•´ì„ ê°€ì´ë“œ ë³´ê¸°"):
        st.markdown(f"""
        - **ğŸ† Top ì €ë„**: Impact Factorê°€ {TOP_JOURNAL_IF_THRESHOLD}ì  ì´ìƒì¸ ê²½ìš° í‘œì‹œë©ë‹ˆë‹¤.
        - **ë§¤ì¹­ ì ìˆ˜**: Google Scholarì˜ ì €ë„ëª…ê³¼ DBì˜ ì €ë„ëª…(ëª¨ë‘ ëŒ€ë¬¸ìí™” í›„ ë¹„êµ) ê°„ì˜ ìœ ì‚¬ë„ì…ë‹ˆë‹¤. ({MATCH_SCORE_THRESHOLD}% ì´ìƒì¼ ë•Œ DB ì •ë³´ í‘œì‹œ)
        - **Impact Factor ë“±ê¸‰**: ìš°ìˆ˜(IF >= 1.0), ì–‘í˜¸(0.5 <= IF < 1.0), ë³´í†µ(0.2 <= IF < 0.5), í•˜ìœ„(IF < 0.2)
        """)

    with st.form(key='search_form'):
        st.subheader("ğŸ” ê²€ìƒ‰ ì¡°ê±´ ì…ë ¥")
        col1, col2 = st.columns(2)
        with col1:
            author = st.text_input("ì €ì (ì„ íƒ ì‚¬í•­)", placeholder="ì˜ˆ: Hinton G")
        with col2:
            keyword = st.text_input("í‚¤ì›Œë“œ (ì„ íƒ ì‚¬í•­)", placeholder="ì˜ˆ: deep learning")

        only_high_impact = st.checkbox("Impact Factor ì •ë³´ê°€ ìˆëŠ” ì €ë„ë§Œ ì°¾ê¸° (DBì—ì„œ ë§¤ì¹­ë˜ëŠ” ì €ë„ë§Œ í‘œì‹œ)", value=True)

        submit_button = st.form_submit_button(label='ê²€ìƒ‰ ì‹œì‘')

    if submit_button and (author or keyword):
        query_parts = []
        if keyword: query_parts.append(keyword)
        if author: query_parts.append(f'author:"{author}"')
        query = " ".join(query_parts)

        with st.spinner(f"'{query}' ì¡°ê±´ìœ¼ë¡œ ë…¼ë¬¸ì„ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                search_query = scholarly.search_pubs(query)
                results = []
                for i, pub in enumerate(search_query):
                    if i >= MAX_RESULTS_LIMIT:
                        st.info(f"ê²€ìƒ‰ ê²°ê³¼ê°€ ë§ì•„ ìµœëŒ€ {MAX_RESULTS_LIMIT}ê°œê¹Œì§€ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
                        break

                    bib = pub.get('bib', {})
                    venue_from_scholar = bib.get('venue', 'N/A')

                    impact_factor_float, matched_db_journal_name_upper, match_score_val = get_journal_info(
                        venue_from_scholar, db_df, journal_names_upper
                    )

                    if only_high_impact and pd.isna(impact_factor_float):
                        continue
                    
                    # Top ì €ë„ ì•„ì´ì½˜: IFê°€ ìˆ«ìì´ê³  ê¸°ì¤€ì  ì´ìƒì¼ ë•Œ
                    top_journal_icon = ""
                    if not pd.isna(impact_factor_float) and impact_factor_float >= TOP_JOURNAL_IF_THRESHOLD:
                        top_journal_icon = "ğŸ†"
                    
                    results.append({
                        "Top ì €ë„": top_journal_icon,
                        "ì œëª© (Title)": bib.get('title', 'N/A'),
                        "ì €ì (Authors)": ", ".join(bib.get('author', ['N/A'])),
                        "ì—°ë„ (Year)": bib.get('pub_year', 'N/A'),
                        "ì €ë„ëª… (ê²€ìƒ‰ê²°ê³¼)": venue_from_scholar,
                        "DB ì €ë„ëª… (ë§¤ì¹­ì‹œ)": matched_db_journal_name_upper,
                        "ë§¤ì¹­ ì ìˆ˜ (%)": match_score_val if match_score_val > 0 else "N/A",
                        "Impact Factor": impact_factor_float if not pd.isna(impact_factor_float) else "N/A", # NaNì´ë©´ "N/A" ë¬¸ìì—´ë¡œ
                        "í”¼ì¸ìš© ìˆ˜": pub.get('num_citations', 0),
                        "ë…¼ë¬¸ ë§í¬": pub.get('pub_url', '#'),
                    })

                if not results:
                    st.warning("ì¡°ê±´ì— ë§ëŠ” ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. (í•„í„°ë¥¼ í•´ì œí•˜ê±°ë‚˜ ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”)")
                else:
                    subheader_text = f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ)"
                    if only_high_impact:
                        subheader_text += " - Impact Factor ì •ë³´ê°€ ìˆëŠ” ì €ë„ë§Œ í•„í„°ë§ë¨"
                    st.subheader(subheader_text)

                    df_results = pd.DataFrame(results)
                    # 'Impact Factor' ì»¬ëŸ¼ì´ ë¬¸ìì—´ "N/A"ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë“±ê¸‰ ë¶„ë¥˜ ì „ì— ìˆ«ìí˜•ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„
                    # get_journal_infoì—ì„œ ì´ë¯¸ float ë˜ëŠ” np.nanìœ¼ë¡œ ë°˜í™˜í•˜ë¯€ë¡œ, df_results['Impact Factor']ë¥¼ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥
                    df_results['IF ë“±ê¸‰'] = df_results['Impact Factor'].apply(
                        lambda x: classify_sjr(x) if x != "N/A" else "N/A"
                    )
                    
                    # Impact Factorë¥¼ í‘œì‹œìš© ë¬¸ìì—´ë¡œ ë³€í™˜ (ì†Œìˆ˜ì  3ìë¦¬ ë˜ëŠ” "N/A")
                    df_display = df_results.copy()
                    df_display['Impact Factor'] = df_display['Impact Factor'].apply(
                        lambda x: f"{x:.3f}" if isinstance(x, float) and not pd.isna(x) and x != 0.05 else ("<0.1" if x==0.05 else "N/A")
                    )


                    df_display = df_display[[
                        "Top ì €ë„", "ì œëª© (Title)", "ì €ì (Authors)", "ì—°ë„ (Year)",
                        "ì €ë„ëª… (ê²€ìƒ‰ê²°ê³¼)", "DB ì €ë„ëª… (ë§¤ì¹­ì‹œ)", "Impact Factor", "IF ë“±ê¸‰",
                        "í”¼ì¸ìš© ìˆ˜", "ë§¤ì¹­ ì ìˆ˜ (%)", "ë…¼ë¬¸ ë§í¬"
                    ]]

                    st.dataframe(
                        df_display.style.applymap(color_sjr_score, subset=['Impact Factor']),
                        use_container_width=True,
                        column_config={"ë…¼ë¬¸ ë§í¬": st.column_config.LinkColumn("ë°”ë¡œê°€ê¸°", display_text="ğŸ”— Link")},
                        hide_index=True
                    )

                    csv_data = convert_df_to_csv(df_display) # í‘œì‹œìš© ë°ì´í„°í”„ë ˆì„ ì‚¬ìš©
                    st.download_button(
                        label="ğŸ“„ ê²°ê³¼ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                        data=csv_data,
                        file_name=f'search_{query.replace(" ", "_").replace(":", "")}.csv',
                        mime='text/csv'
                    )
            except Exception as e:
                st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)
    elif submit_button and not (author or keyword):
        st.warning("ì €ì ë˜ëŠ” í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ ì´ìƒì„ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
