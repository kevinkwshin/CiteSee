import streamlit as st
import pandas as pd
from scholarly import scholarly
import io
from thefuzz import process, fuzz
import os

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ë…¼ë¬¸ ê²€ìƒ‰ ë‹¤ìš´ë¡œë”",
    page_icon="ğŸ“š",
    layout="wide",
)

# --- 2. í•µì‹¬ í•¨ìˆ˜ (ë°ì´í„° ë¡œë”©, ë§¤ì¹­, ìŠ¤íƒ€ì¼ë§) ---
@st.cache_data
def load_journal_db(file_path='journal_if_data.csv'):
    if not os.path.exists(file_path):
        return None, None
    try:
        df = pd.read_csv(file_path)
        df.dropna(subset=['FullName', 'ImpactFactor'], inplace=True)
        return df, df['FullName'].tolist()
    except Exception as e:
        st.error(f"ë°ì´í„° íŒŒì¼({file_path}) ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None, None

@st.cache_data
def get_journal_info(venue, db_df, journal_names_list):
    if not venue or db_df is None or not journal_names_list:
        return "N/A"
    match, score = process.extractOne(venue, journal_names_list, scorer=fuzz.token_sort_ratio)
    if score >= 80:
        sjr_value = db_df.loc[db_df['FullName'] == match, 'ImpactFactor'].iloc[0]
        return f"{sjr_value:.3f}"
    return "N/A"

# â­ï¸ ìƒˆë¡œìš´ ê¸°ëŠ¥: SJR ì ìˆ˜ë¥¼ ë“±ê¸‰ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def classify_sjr(sjr_score_str):
    if sjr_score_str == "N/A":
        return "N/A"
    try:
        score = float(sjr_score_str)
        if score >= 1.0:
            return "ìš°ìˆ˜"
        elif 0.5 <= score < 1.0:
            return "ì–‘í˜¸"
        elif 0.2 <= score < 0.5:
            return "ë³´í†µ"
        else:
            return "í•˜ìœ„"
    except (ValueError, TypeError):
        return "N/A"

# â­ï¸ ìƒˆë¡œìš´ ê¸°ëŠ¥: SJR ì ìˆ˜ ê°’ì— ë”°ë¼ ìƒ‰ìƒì„ ì…íˆëŠ” í•¨ìˆ˜
def color_sjr_score(val):
    try:
        score = float(val)
        if score >= 1.0:
            color = 'green'
        elif 0.5 <= score < 1.0:
            color = 'blue'
        elif 0.2 <= score < 0.5:
            color = 'orange'
        else:
            color = 'red'
        return f'color: {color}; font-weight: bold;'
    except (ValueError, TypeError):
        return 'color: grey;'

@st.cache_data
def convert_df_to_csv(df: pd.DataFrame):
    return df.to_csv(index=False).encode('utf-8-sig')


# --- 3. UI ë³¸ë¬¸ êµ¬ì„± ---
st.title("ğŸ“š ë…¼ë¬¸ ê²€ìƒ‰ ë° ì •ë³´ ë‹¤ìš´ë¡œë”")
st.markdown("Google Scholarì—ì„œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³ , **SJR(Scimago Journal Rank) ì§€í‘œ**ë¥¼ í•¨ê»˜ ì¡°íšŒí•˜ì—¬ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")

db_df, journal_names = load_journal_db()
if db_df is None:
    st.error("âš ï¸ `journal_if_data.csv` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `scrape_if_data.py`ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
else:
    st.success(f"âœ… ì´ {len(db_df):,}ê°œì˜ ì €ë„ ì •ë³´ê°€ ë‹´ê¸´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    
    # â­ï¸ ìƒˆë¡œìš´ ê¸°ëŠ¥: í¼ì³ë³¼ ìˆ˜ ìˆëŠ” SJR í•´ì„ ê°€ì´ë“œ
    with st.expander("ğŸ’¡ SJR ì ìˆ˜ í•´ì„ ê°€ì´ë“œ ë³´ê¸°"):
        st.markdown("""
        SJR(Scimago Journal Rank)ì€ ì €ë„ì˜ ê³¼í•™ì  ì˜í–¥ë ¥ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì…ë‹ˆë‹¤. 
        - **<span style='color:green;'>1.0 ì´ìƒ</span>**: í•´ë‹¹ ë¶„ì•¼ì—ì„œ ë§¤ìš° ì˜í–¥ë ¥ ìˆëŠ” ìš°ìˆ˜í•œ ì €ë„
        - **<span style='color:blue;'>0.5 ~ 1.0</span>**: ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–‘í˜¸í•œ ì €ë„
        - **<span style='color:orange;'>0.2 ~ 0.5</span>**: ë³´í†µ ìˆ˜ì¤€ì˜ ì €ë„
        - **<span style='color:red;'>0.2 ë¯¸ë§Œ</span>**: ë¹„êµì  ì˜í–¥ë ¥ì´ ë‚®ì€ ì €ë„
        
        <small>*ì°¸ê³ : ì´ ê¸°ì¤€ì€ ì¼ë°˜ì ì¸ ê°€ì´ë“œì´ë©°, í•™ë¬¸ ë¶„ì•¼ë³„ í¸ì°¨ëŠ” í´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.*</small>
        """, unsafe_allow_html=True)

    with st.form(key='search_form'):
        st.subheader("ğŸ” ê²€ìƒ‰ ì¡°ê±´ ì…ë ¥")
        col1, col2 = st.columns(2)
        with col1:
            author = st.text_input("ì €ì (ì„ íƒ ì‚¬í•­)", placeholder="ì˜ˆ: Hinton G")
        with col2:
            keyword = st.text_input("í‚¤ì›Œë“œ (ì„ íƒ ì‚¬í•­)", placeholder="ì˜ˆ: deep learning")
        num_results = st.slider("ê°€ì ¸ì˜¬ ë…¼ë¬¸ ìˆ˜", min_value=5, max_value=50, value=10)
        submit_button = st.form_submit_button(label='ê²€ìƒ‰ ì‹œì‘')

    if submit_button and (author or keyword):
        query_parts = []
        if keyword: query_parts.append(keyword)
        if author: query_parts.append(f'author:"{author}"')
        query = " ".join(query_parts)

        with st.spinner(f"'{query}' ì¡°ê±´ìœ¼ë¡œ ë…¼ë¬¸ì„ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                search_query = scholarly.search_pubs(query)
                results = []
                for i, pub in enumerate(search_query):
                    if i >= num_results: break
                    bib = pub.get('bib', {})
                    venue = bib.get('venue', 'N/A')
                    sjr_score = get_journal_info(venue, db_df, journal_names)
                    
                    results.append({
                        "ì œëª© (Title)": bib.get('title', 'N/A'),
                        "ì €ì (Authors)": ", ".join(bib.get('author', ['N/A'])),
                        "ì—°ë„ (Year)": bib.get('pub_year', 'N/A'),
                        "ì €ë„ (Venue)": venue,
                        "ì €ë„ SJR": sjr_score,
                        "í”¼ì¸ìš© ìˆ˜": pub.get('num_citations', 0),
                        "ë…¼ë¬¸ ë§í¬": pub.get('pub_url', '#'),
                    })

                if not results:
                    st.warning("ê²€ìƒ‰ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.subheader("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼")
                    df = pd.DataFrame(results)
                    # â­ï¸ ìƒˆë¡œìš´ ê¸°ëŠ¥: SJR ë“±ê¸‰ ì»¬ëŸ¼ ì¶”ê°€
                    df['SJR ë“±ê¸‰'] = df['ì €ë„ SJR'].apply(classify_sjr)
                    # ì»¬ëŸ¼ ìˆœì„œ ì¬ë°°ì¹˜
                    df = df[["ì œëª© (Title)", "ì €ì (Authors)", "ì—°ë„ (Year)", "ì €ë„ (Venue)", "ì €ë„ SJR", "SJR ë“±ê¸‰", "í”¼ì¸ìš© ìˆ˜", "ë…¼ë¬¸ ë§í¬"]]
                    
                    # â­ï¸ ìƒˆë¡œìš´ ê¸°ëŠ¥: ë°ì´í„°í”„ë ˆì„ì— ìŠ¤íƒ€ì¼(ìƒ‰ìƒ) ì ìš©
                    st.dataframe(
                        df.style.applymap(color_sjr_score, subset=['ì €ë„ SJR']),
                        use_container_width=True,
                        column_config={"ë…¼ë¬¸ ë§í¬": st.column_config.LinkColumn("ë°”ë¡œê°€ê¸°", display_text="ğŸ”— Link")},
                        hide_index=True
                    )
                    
                    st.download_button(
                        label="ğŸ“„ ê²°ê³¼ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                        data=convert_df_to_csv(df),
                        file_name=f'search_{query.replace(" ", "_").replace(":", "")}.csv',
                        mime='text/csv'
                    )
            except Exception as e:
                st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    elif submit_button and not (author or keyword):
        st.warning("ì €ì ë˜ëŠ” í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ ì´ìƒì„ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
