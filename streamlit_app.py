import streamlit as st
import pandas as pd
from scholarly import scholarly
import io
from thefuzz import process, fuzz
import os

# --- 1. í˜ì´ì§€ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜ ---
st.set_page_config(
    page_title="ë…¼ë¬¸ ê²€ìƒ‰ ë‹¤ìš´ë¡œë”",
    page_icon="ğŸ“š",
    layout="wide",
)

MAX_RESULTS_LIMIT = 200
MATCH_SCORE_THRESHOLD = 95 # ì €ë„ëª… ë§¤ì¹­ ì„ê³„ê°’ì„ 95ë¡œ ìƒí–¥ ì¡°ì • (ë” ì—„ê²©í•œ ë§¤ì¹­)

# ì œê³µëœ CSVì˜ journal_title ì»¬ëŸ¼ ê°’ê³¼ ì¼ì¹˜í•˜ë„ë¡ ëŒ€ë¬¸ìë¡œ ë³€ê²½
TOP_JOURNALS = {
    "NATURE", "SCIENCE", "CELL", "THE LANCET", "NEW ENGLAND JOURNAL OF MEDICINE",
    "CA - A CANCER JOURNAL FOR CLINICIANS", "NATURE REVIEWS MOLECULAR CELL BIOLOGY",
    "NATURE MEDICINE", "THE LANCET NEUROLOGY", "JAMA - JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION"
}
# ì œê³µëœ CSV íŒŒì¼ëª…
JOURNAL_DATA_FILE = 'journal_impact_data_20250619_153150.csv'

# --- 2. í•µì‹¬ í•¨ìˆ˜ (ë°ì´í„° ë¡œë”©, ë§¤ì¹­, ìŠ¤íƒ€ì¼ë§) ---
@st.cache_data
def load_journal_db(file_path=JOURNAL_DATA_FILE):
    if not os.path.exists(file_path):
        return None, None
    try:
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        df.dropna(subset=['journal_title', 'impact_factor'], inplace=True)
        # journal_titleì„ ë¬¸ìì—´ë¡œ ëª…ì‹œì  ë³€í™˜ (í˜¹ì‹œ ëª¨ë¥¼ ìˆ«ìí˜• ì €ë„ëª… ë°©ì§€)
        df['journal_title'] = df['journal_title'].astype(str)
        return df, df['journal_title'].tolist()
    except Exception as e:
        st.error(f"ë°ì´í„° íŒŒì¼({file_path}) ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None, None

@st.cache_data
def get_journal_info(venue, db_df, journal_names_list):
    if not venue or db_df is None or not journal_names_list:
        return "N/A", "N/A", 0

    # Google Scholar ì €ë„ëª… ì „ì²˜ë¦¬ (ì˜µì…˜): ì–‘ìª½ ê³µë°± ì œê±°, ì†Œë¬¸ìí™”
    # ì´ëŠ” DBì˜ journal_names_listë„ ë™ì¼í•˜ê²Œ ì „ì²˜ë¦¬ë˜ì—ˆì„ ë•Œ íš¨ê³¼ì ì…ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” DBì˜ journal_titleì´ ëŒ€ë¶€ë¶„ ëŒ€ë¬¸ìì´ë¯€ë¡œ, venueë„ ëŒ€ë¬¸ìë¡œ í†µì¼í•©ë‹ˆë‹¤.
    processed_venue = str(venue).strip().upper()
    if not processed_venue: # ì „ì²˜ë¦¬ í›„ ë¹ˆ ë¬¸ìì—´ì´ ë˜ë©´ ë§¤ì¹­ ë¶ˆê°€
        return "N/A", "N/A", 0

    # TheFuzzë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ì €ë„ëª… ì°¾ê¸°
    # journal_names_listëŠ” ì´ë¯¸ ëŒ€ë¬¸ì ìœ„ì£¼ì¼ ê²ƒì´ë¯€ë¡œ, processed_venueì™€ ë¹„êµ
    match, score = process.extractOne(processed_venue, journal_names_list, scorer=fuzz.ratio) # scorerë¥¼ ratioë¡œ ë³€ê²½ (ë‹¨ìˆœ ìœ ì‚¬ë„)

    # ì ìˆ˜ê°€ ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ì—ë§Œ ì •ë³´ ë°˜í™˜
    if score >= MATCH_SCORE_THRESHOLD:
        # ì°¾ì€ match(DBì˜ ì €ë„ëª…)ë¥¼ ì‚¬ìš©í•˜ì—¬ Impact Factor ì¡°íšŒ
        # db_df['journal_title']ë„ ëŒ€ë¬¸ìë¡œ ì¼ê´€ì„± ìˆê²Œ ë¹„êµ (load_journal_dbì—ì„œ ì´ë¯¸ ëŒ€ë¬¸ìë¡œ í†µì¼í–ˆë‹¤ë©´ í•„ìš” ì—†ìŒ)
        # ì—¬ê¸°ì„œëŠ” journal_names_listê°€ db_df['journal_title']ì—ì„œ ì™”ìœ¼ë¯€ë¡œ matchëŠ” DBì˜ ì›ë³¸ í˜•íƒœë¥¼ ê°€ì§
        impact_factor_series = db_df.loc[db_df['journal_title'] == match, 'impact_factor']
        if not impact_factor_series.empty:
            impact_factor_value = impact_factor_series.iloc[0]
            if isinstance(impact_factor_value, (int, float)):
                return f"{impact_factor_value:.3f}", match, score
            else: # '<0.1'ê³¼ ê°™ì€ ë¬¸ìì—´ ê°’ ì²˜ë¦¬
                return str(impact_factor_value), match, score
        else: # ì´ë¡ ì ìœ¼ë¡œëŠ” extractOneì´ journal_names_listì—ì„œ ì°¾ìœ¼ë¯€ë¡œ ì´ ê²½ìš°ëŠ” ë“œë¬¼ì§€ë§Œ, ì•ˆì „ì¥ì¹˜
            return "N/A", "DB ì¡°íšŒ ì‹¤íŒ¨", score
    else:
        return "N/A", "ë§¤ì¹­ ì‹¤íŒ¨", score


def classify_sjr(sjr_score_str):
    if sjr_score_str == "N/A" or sjr_score_str == "<0.1":
        return "N/A"
    try:
        score = float(sjr_score_str)
        if score >= 1.0: return "ìš°ìˆ˜"
        elif 0.5 <= score < 1.0: return "ì–‘í˜¸"
        elif 0.2 <= score < 0.5: return "ë³´í†µ"
        else: return "í•˜ìœ„"
    except (ValueError, TypeError):
        return "N/A"

def color_sjr_score(val):
    try:
        if val == "<0.1":
            score = 0.05
        else:
            score = float(val)

        if score >= 1.0: color = 'green'
        elif 0.5 <= score < 1.0: color = 'blue'
        elif 0.2 <= score < 0.5: color = 'orange'
        else: color = 'red'
        return f'color: {color}; font-weight: bold;'
    except (ValueError, TypeError):
        return 'color: grey;'

@st.cache_data
def convert_df_to_csv(df: pd.DataFrame):
    return df.to_csv(index=False).encode('utf-8-sig')


# --- 3. UI ë³¸ë¬¸ êµ¬ì„± ---
st.title("ğŸ“š ë…¼ë¬¸ ê²€ìƒ‰ ë° ì •ë³´ ë‹¤ìš´ë¡œë”")
st.markdown(f"""
Google Scholarì—ì„œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³ , Impact Factorë¥¼ í•¨ê»˜ ì¡°íšŒí•©ë‹ˆë‹¤. (ìµœëŒ€ **{MAX_RESULTS_LIMIT}ê°œ**ê¹Œì§€ í‘œì‹œ)

**ì €ë„ëª… ë§¤ì¹­ ì •í™•ë„:** Google Scholarì˜ ì €ë„ëª…ê³¼ ë‚´ë¶€ DBì˜ ì €ë„ëª… ê°„ ìœ ì‚¬ë„ ì ìˆ˜ê°€ **{MATCH_SCORE_THRESHOLD}% ì´ìƒ**ì¼ ê²½ìš°ì—ë§Œ Impact Factorë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
""")

db_df, journal_names = load_journal_db()
if db_df is None:
    st.error(f"âš ï¸ `{JOURNAL_DATA_FILE}` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•±ê³¼ ë™ì¼í•œ í´ë”ì— í•´ë‹¹ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    st.success(f"âœ… ì´ {len(db_df):,}ê°œì˜ ì €ë„ ì •ë³´ê°€ ë‹´ê¸´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    with st.expander("ğŸ’¡ ê²°ê³¼ í…Œì´ë¸” í•´ì„ ê°€ì´ë“œ ë³´ê¸°"):
        st.markdown(f"""
        - **ğŸ† Top ì €ë„**: `{', '.join(list(TOP_JOURNALS)[:3])}` ë“± ì„¸ê³„ ìµœìƒìœ„ ì €ë„ì„ íŠ¹ë³„íˆ í‘œì‹œí•©ë‹ˆë‹¤. (DBì— í•´ë‹¹ ì €ë„ì´ ìˆê³ , ë§¤ì¹­ëœ ê²½ìš°)
        - **ë§¤ì¹­ ì ìˆ˜**: Google Scholarì˜ ì €ë„ëª…ê³¼ DBì˜ ì €ë„ëª… ê°„ì˜ ìœ ì‚¬ë„ì…ë‹ˆë‹¤. (í˜„ì¬ {MATCH_SCORE_THRESHOLD}% ì´ìƒ ë§¤ì¹­)
        - **Impact Factor ë“±ê¸‰**: ìš°ìˆ˜(IF >= 1.0), ì–‘í˜¸(0.5 <= IF < 1.0), ë³´í†µ(0.2 <= IF < 0.5), í•˜ìœ„(IF < 0.2)
        """)

    with st.form(key='search_form'):
        st.subheader("ğŸ” ê²€ìƒ‰ ì¡°ê±´ ì…ë ¥")
        col1, col2 = st.columns(2)
        with col1:
            author = st.text_input("ì €ì (ì„ íƒ ì‚¬í•­)", placeholder="ì˜ˆ: Hinton G")
        with col2:
            keyword = st.text_input("í‚¤ì›Œë“œ (ì„ íƒ ì‚¬í•­)", placeholder="ì˜ˆ: deep learning")

        only_high_impact = st.checkbox("Impact Factor ì •ë³´ê°€ ìˆëŠ” ì €ë„ë§Œ ì°¾ê¸° (DBì—ì„œ ë§¤ì¹­ë˜ëŠ” ì €ë„ë§Œ í‘œì‹œ)", value=True)

        submit_button = st.form_submit_button(label='ê²€ìƒ‰ ì‹œì‘')

    if submit_button and (author or keyword):
        query_parts = []
        if keyword: query_parts.append(keyword)
        if author: query_parts.append(f'author:"{author}"')
        query = " ".join(query_parts)

        with st.spinner(f"'{query}' ì¡°ê±´ìœ¼ë¡œ ë…¼ë¬¸ì„ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                search_query = scholarly.search_pubs(query)
                results = []
                for i, pub in enumerate(search_query):
                    if i >= MAX_RESULTS_LIMIT:
                        st.info(f"ê²€ìƒ‰ ê²°ê³¼ê°€ ë§ì•„ ìµœëŒ€ {MAX_RESULTS_LIMIT}ê°œê¹Œì§€ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
                        break

                    bib = pub.get('bib', {})
                    venue = bib.get('venue', 'N/A')

                    if not isinstance(venue, str) or not venue.strip():
                        impact_factor, matched_name, match_score = "N/A", "N/A", 0
                    else:
                        impact_factor, matched_name, match_score = get_journal_info(venue, db_df, journal_names)

                    if only_high_impact and impact_factor == "N/A":
                        continue

                    top_journal_icon = "ğŸ†" if matched_name in TOP_JOURNALS else ""

                    results.append({
                        "Top ì €ë„": top_journal_icon,
                        "ì œëª© (Title)": bib.get('title', 'N/A'),
                        "ì €ì (Authors)": ", ".join(bib.get('author', ['N/A'])),
                        "ì—°ë„ (Year)": bib.get('pub_year', 'N/A'),
                        "ê²€ìƒ‰ëœ ì €ë„ëª… (ì¶•ì•½)": venue,
                        "ë§¤ì¹­ëœ ì €ë„ëª… (DB)": matched_name,
                        "ë§¤ì¹­ ì ìˆ˜ (%)": match_score if match_score > 0 else "N/A", # 0ì ì€ N/Aë¡œ í‘œì‹œ
                        "Impact Factor": impact_factor,
                        "í”¼ì¸ìš© ìˆ˜": pub.get('num_citations', 0),
                        "ë…¼ë¬¸ ë§í¬": pub.get('pub_url', '#'),
                    })

                if not results:
                    st.warning("ì¡°ê±´ì— ë§ëŠ” ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. (í•„í„°ë¥¼ í•´ì œí•˜ê±°ë‚˜ ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”)")
                else:
                    subheader_text = f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ)"
                    if only_high_impact:
                        subheader_text += " - Impact Factor ì •ë³´ê°€ ìˆëŠ” ì €ë„ë§Œ í•„í„°ë§ë¨"
                    st.subheader(subheader_text)

                    df_results = pd.DataFrame(results)
                    df_results['IF ë“±ê¸‰'] = df_results['Impact Factor'].apply(classify_sjr)
                    df_results = df_results[[
                        "Top ì €ë„", "ì œëª© (Title)", "ì €ì (Authors)", "ì—°ë„ (Year)",
                        "ë§¤ì¹­ëœ ì €ë„ëª… (DB)", "Impact Factor", "IF ë“±ê¸‰",
                        "í”¼ì¸ìš© ìˆ˜", "ë§¤ì¹­ ì ìˆ˜ (%)", "ê²€ìƒ‰ëœ ì €ë„ëª… (ì¶•ì•½)", "ë…¼ë¬¸ ë§í¬"
                    ]]

                    st.dataframe(
                        df_results.style.applymap(color_sjr_score, subset=['Impact Factor']),
                        use_container_width=True,
                        column_config={"ë…¼ë¬¸ ë§í¬": st.column_config.LinkColumn("ë°”ë¡œê°€ê¸°", display_text="ğŸ”— Link")},
                        hide_index=True
                    )

                    csv_data = convert_df_to_csv(df_results)
                    st.download_button(
                        label="ğŸ“„ ê²°ê³¼ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                        data=csv_data,
                        file_name=f'search_{query.replace(" ", "_").replace(":", "")}.csv',
                        mime='text/csv'
                    )
            except Exception as e:
                st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)
    elif submit_button and not (author or keyword):
        st.warning("ì €ì ë˜ëŠ” í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ ì´ìƒì„ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
